This repository contains a basic implementation of a Generative Pre-trained Transformer and a baseline bigram language model. The project consists of two main files. The bigramModel.py file contains the code for a simple baseline bigram language model. The gpt_dev.ipynb notebook contains the step-by-step development and implementation of the GPT model architecture built from scratch.
